{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport glob\nimport pickle\nimport seaborn as sns\nfrom keras.layers import Dense\nfrom keras.utils.vis_utils import plot_model\nimport cv2\nimport os\nimport pandas as pd\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-04-09T21:56:44.891198Z","iopub.execute_input":"2022-04-09T21:56:44.892792Z","iopub.status.idle":"2022-04-09T21:56:44.901772Z","shell.execute_reply.started":"2022-04-09T21:56:44.892756Z","shell.execute_reply":"2022-04-09T21:56:44.900683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize hyperparameters.\nEPOCHS = 1000\nINIT_LR = 1e-3\nDECAY = 1e-6\nBS = 32\ndefault_image_size = tuple((256, 256))\nresized_image_size = tuple((224,224))\nimage_size = 0\ndirectory_root = '../input/plantvillage'","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:44.965451Z","iopub.execute_input":"2022-04-09T21:56:44.965829Z","iopub.status.idle":"2022-04-09T21:56:44.97312Z","shell.execute_reply.started":"2022-04-09T21:56:44.965782Z","shell.execute_reply":"2022-04-09T21:56:44.970417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to convert image to array.\ndef convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, resized_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:45.033135Z","iopub.execute_input":"2022-04-09T21:56:45.033791Z","iopub.status.idle":"2022-04-09T21:56:45.040428Z","shell.execute_reply.started":"2022-04-09T21:56:45.033752Z","shell.execute_reply":"2022-04-09T21:56:45.039434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the images from the dataset folder.\nimage_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list[:100]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed!\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:45.104085Z","iopub.execute_input":"2022-04-09T21:56:45.104692Z","iopub.status.idle":"2022-04-09T21:56:51.327136Z","shell.execute_reply.started":"2022-04-09T21:56:45.104644Z","shell.execute_reply":"2022-04-09T21:56:51.325998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = len(image_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:51.329432Z","iopub.execute_input":"2022-04-09T21:56:51.329689Z","iopub.status.idle":"2022-04-09T21:56:51.335286Z","shell.execute_reply.started":"2022-04-09T21:56:51.329661Z","shell.execute_reply":"2022-04-09T21:56:51.334257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign the classes to images.\nlabel_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\nn_classes = len(label_binarizer.classes_)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:51.337048Z","iopub.execute_input":"2022-04-09T21:56:51.337731Z","iopub.status.idle":"2022-04-09T21:56:51.3571Z","shell.execute_reply.started":"2022-04-09T21:56:51.337632Z","shell.execute_reply":"2022-04-09T21:56:51.356167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the array to a NumPy list and normalise it.\nnp_image_list = np.array(image_list, dtype = np.float16) / 223.0","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:51.359444Z","iopub.execute_input":"2022-04-09T21:56:51.359741Z","iopub.status.idle":"2022-04-09T21:56:56.460682Z","shell.execute_reply.started":"2022-04-09T21:56:51.359701Z","shell.execute_reply":"2022-04-09T21:56:56.459625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Spliting data to train, test, and valid\")\n\n\nratio_train = 0.80\nratio_val = 0.10\nratio_test = 0.10\n\n# Produces test split.\nx_remaining, x_test, y_remaining, y_test = train_test_split(\n    np_image_list, image_labels, test_size=ratio_test , random_state = 42)\n\n# Adjusts val ratio, w.r.t. remaining dataset.\nratio_remaining = 1 - ratio_test\nratio_val_adjusted = ratio_val / ratio_remaining\n\n# Produces train and val splits.\nx_train, x_val, y_train, y_val = train_test_split(\n    x_remaining, y_remaining, test_size=ratio_val_adjusted , random_state = 42)\n\n\nprint(\"x_train: \", len(x_train))\nprint(\"x_val: \", len(x_val))\nprint(\"x_test: \", len(x_test))\n\nprint(len(y_train))\nprint(len(y_val))\nprint(len(y_test))\n\n# x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, \n#                                                     random_state = 42) ","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:56.462547Z","iopub.execute_input":"2022-04-09T21:56:56.462898Z","iopub.status.idle":"2022-04-09T21:56:56.786465Z","shell.execute_reply.started":"2022-04-09T21:56:56.462829Z","shell.execute_reply":"2022-04-09T21:56:56.785325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2, \n    zoom_range = 0.2,\n    horizontal_flip = True, \n    fill_mode = \"nearest\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:56.788445Z","iopub.execute_input":"2022-04-09T21:56:56.788765Z","iopub.status.idle":"2022-04-09T21:56:56.795563Z","shell.execute_reply.started":"2022-04-09T21:56:56.788722Z","shell.execute_reply":"2022-04-09T21:56:56.794285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model.\nmodel = Sequential()\n          \n# 1st Convolutional Layer\nmodel.add(Conv2D(filters = 96, input_shape = (224,224,3), kernel_size = (11,11), strides = (4,4), padding = 'valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\n# Pooling Layer\nmodel.add(MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid'))\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters = 256, kernel_size = (5,5), strides = (1,1), padding = 'same'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n# Pooling Layer\nmodel.add(MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid'))\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = 'same'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n# Dropout\nmodel.add(Dropout(0.5))\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = 'same'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n# Dropout\nmodel.add(Dropout(0.5))\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3), strides = (1,1), padding = 'same'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n# Pooling Layer\nmodel.add(MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid'))\n# Dropout\nmodel.add(Dropout(0.5))\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape = (224*224*3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.25))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.5))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.5))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(n_classes))\nmodel.add(Activation('softmax'))\n\n# Get the model summary.\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:56.797945Z","iopub.execute_input":"2022-04-09T21:56:56.798174Z","iopub.status.idle":"2022-04-09T21:56:57.114248Z","shell.execute_reply.started":"2022-04-09T21:56:56.798147Z","shell.execute_reply":"2022-04-09T21:56:57.113249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile \nopt = Adam(lr = INIT_LR, decay = INIT_LR/EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer = opt,metrics = [\"accuracy\"])\nprint(\"[INFO] Training network...\")\n\n# Train\ncheckpoint = ModelCheckpoint(\"AlexNet.h5\", monitor = 'accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\n\nhistory = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size = BS, shuffle = False),\n    validation_data = (x_val, y_val),\n    steps_per_epoch = len(x_train) // BS,\n    callbacks = [checkpoint],\n    epochs = EPOCHS,\n    verbose=1 )","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:56:57.116473Z","iopub.execute_input":"2022-04-09T21:56:57.116813Z","iopub.status.idle":"2022-04-10T02:45:23.351161Z","shell.execute_reply.started":"2022-04-09T21:56:57.116753Z","shell.execute_reply":"2022-04-10T02:45:23.348815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# average accuracy\nmean_acc = np.mean(history.history['accuracy'])\nprint(mean_acc)\nmax_acc = np.max(history.history['accuracy'])\nprint(max_acc)\n# min_acc = np.mean(history.history['accuracy'])\n# print(min_acc)\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T02:45:23.353319Z","iopub.execute_input":"2022-04-10T02:45:23.35468Z","iopub.status.idle":"2022-04-10T02:45:23.893255Z","shell.execute_reply.started":"2022-04-10T02:45:23.354629Z","shell.execute_reply":"2022-04-10T02:45:23.892147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T02:45:23.898522Z","iopub.execute_input":"2022-04-10T02:45:23.898766Z","iopub.status.idle":"2022-04-10T02:45:24.35245Z","shell.execute_reply.started":"2022-04-10T02:45:23.898735Z","shell.execute_reply":"2022-04-10T02:45:24.351457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[INFO] Saving model...\")\nmodel.save(\"new_model_An.h5\")\nprint(\"[INFO] Saved model to disk!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T02:45:24.35405Z","iopub.execute_input":"2022-04-10T02:45:24.354688Z","iopub.status.idle":"2022-04-10T02:45:25.549187Z","shell.execute_reply.started":"2022-04-10T02:45:24.354639Z","shell.execute_reply":"2022-04-10T02:45:25.548149Z"},"trusted":true},"execution_count":null,"outputs":[]}]}